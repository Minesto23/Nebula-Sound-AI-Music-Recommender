# üìò Documentaci√≥n del Proyecto: Nebula Sound

## üìã Descripci√≥n General

**Nebula Sound** es un sistema inteligente de recomendaci√≥n musical basado en metadatos. Su objetivo es sugerir canciones y generar playlists personalizadas sin necesidad de analizar el audio directamente, utilizando en su lugar caracter√≠sticas ac√∫sticas y metadatos textuales extra√≠dos de un dataset de Spotify.

### ¬øQu√© hace?
- Encuentra canciones similares a una "canci√≥n semilla".
- Genera playlists autom√°ticas de tama√±o configurable.
- Permite la b√∫squeda de artistas y sus discograf√≠as.
- Ofrece una interfaz visual interactiva y una API backend robusta.

### ¬øPara qu√© sirve?
Sirve como motor de descubrimiento musical y demostraci√≥n t√©cnica de un pipeline completo de Machine Learning, desde la ingenier√≠a de caracter√≠sticas hasta el despliegue en producci√≥n con Docker.

### P√∫blico Objetivo
- **Usuarios finales**: Amantes de la m√∫sica que desean descubrir nuevas canciones.
- **Desarrolladores y Data Scientists**: Interesados en sistemas de recomendaci√≥n, procesamiento de lenguaje natural (NLP) aplicado a metadatos y arquitectura de software modular.

---

## üèóÔ∏è Arquitectura del Proyecto

El proyecto sigue una arquitectura modular desacoplada, separando la l√≥gica de entrenamiento, el backend de servicio y la interfaz de usuario.

### Estructura de Carpetas

```bash
Nebula-Sound-AI-Music-Recommender/
‚îÇ‚îÄ‚îÄ backend/                 # L√≥gica del servidor y API
‚îÇ    ‚îú‚îÄ‚îÄ main.py             # Definici√≥n de endpoints (FastAPI)
‚îÇ    ‚îî‚îÄ‚îÄ recommender.py      # L√≥gica de inferencia y carga de modelos
‚îÇ
‚îÇ‚îÄ‚îÄ model/                   # Entrenamiento y artefactos del modelo
‚îÇ    ‚îú‚îÄ‚îÄ train_model.py      # Script de entrenamiento y limpieza de datos
‚îÇ    ‚îú‚îÄ‚îÄ cleaned_spotify.csv # Dataset procesado
‚îÇ    ‚îî‚îÄ‚îÄ *.pkl               # Modelos serializados (KNN, Scaler, TF-IDF)
‚îÇ
‚îÇ‚îÄ‚îÄ ui/                      # Interfaz de usuario
‚îÇ    ‚îî‚îÄ‚îÄ app.py              # Aplicaci√≥n interactiva (Gradio)
‚îÇ
‚îÇ‚îÄ‚îÄ data/                    # Datos crudos (entrada)
‚îÇ‚îÄ‚îÄ Dockerfile               # Configuraci√≥n para contenedorizaci√≥n
‚îÇ‚îÄ‚îÄ requirements.txt         # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md                # Informaci√≥n b√°sica
```

### Flujo General del Sistema
1.  **Entrenamiento (Offline)**:
    - Se carga el dataset de Spotify (`data/`).
    - Se limpian los datos y se crean caracter√≠sticas h√≠bridas (texto + num√©ricas).
    - Se entrena un modelo KNN y se serializan los artefactos en `model/`.
2.  **Inferencia (Online)**:
    - Al iniciar, el backend carga los modelos `.pkl` en memoria.
    - El usuario env√≠a una consulta (nombre de canci√≥n) v√≠a UI o API.
    - El sistema vectoriza la consulta y busca los vecinos m√°s cercanos usando similitud coseno.
    - Se devuelven los resultados enriquecidos con metadatos.

### Componentes Principales

| Componente | Responsabilidad |
| :--- | :--- |
| **`model/train_model.py`** | Pipeline ETL: limpieza, vectorizaci√≥n (TF-IDF), escalado (StandardScaler) y entrenamiento del modelo KNN. |
| **`backend/recommender.py`** | Carga los modelos entrenados y expone funciones core (`recommend_songs`, `generate_playlist`) para ser usadas por la API o la UI. Maneja la l√≥gica de b√∫squeda fuzzy. |
| **`backend/main.py`** | Servidor API REST que expone la funcionalidad al mundo exterior. |
| **`ui/app.py`** | Interfaz gr√°fica amigable construida con Gradio para interactuar con el sistema visualmente. |

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Lenguajes
- **Python 3.9+**: Lenguaje principal para todo el desarrollo.

### Frameworks y Librer√≠as
- **FastAPI**: Para la creaci√≥n del backend API REST de alto rendimiento.
- **Gradio**: Para la construcci√≥n r√°pida de la interfaz de usuario de demostraci√≥n.
- **Scikit-learn**: Para los algoritmos de ML (KNN, StandardScaler, TF-IDF).
- **Pandas & NumPy**: Para manipulaci√≥n y an√°lisis eficiente de datos estructurados.
- **RapidFuzz**: Para b√∫squeda difusa (fuzzy search) de nombres de canciones y artistas.
- **Uvicorn**: Servidor ASGI para ejecutar FastAPI.

### Herramientas
- **Docker / Podman**: Para empaquetado y despliegue consistente.

---

## ‚öôÔ∏è Instalaci√≥n y Configuraci√≥n

### Requisitos Previos
- Python 3.9 o superior instalado.
- (Opcional) Docker o Podman si se prefiere ejecuci√≥n en contenedor.

### Pasos para Instalar

1.  **Clonar el repositorio:**
    ```bash
    git clone <url-del-repo>
    cd Nebula-Sound-AI-Music-Recommender
    ```

2.  **Crear un entorno virtual (recomendado):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # En Linux/Mac
    # venv\Scripts\activate   # En Windows
    ```

3.  **Instalar dependencias:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Entrenar el modelo (inicializaci√≥n):**
    Antes de ejecutar la app, es necesario generar los artefactos del modelo si no existen.
    ```bash
    python model/train_model.py
    ```

### Variables de Entorno
El proyecto actualmente no requiere configuraci√≥n compleja mediante variables de entorno `.env` para su funcionamiento b√°sico local.

---

## üöÄ Uso del Proyecto

### C√≥mo ejecutarlo

Hay dos formas principales de usar el sistema: a trav√©s de la **Interfaz Gr√°fica (UI)** o mediante la **API Backend**.

#### Opci√≥n A: Interfaz Gr√°fica (Gradio)
Es la forma m√°s f√°cil de probar el sistema.
```bash
python ui/app.py
```
- Abrir navegador tras la ejecuci√≥n (usualmente `http://127.0.0.1:7860`).
- Navegar entre pesta√±as: "Song Recommendations", "Playlist Generator", "Search by Artist".

#### Opci√≥n B: API Backend (FastAPI)
Para integraciones o pruebas t√©cnicas.
```bash
uvicorn backend.main:app --reload
```
- Documentaci√≥n interactiva disponible en `http://127.0.0.1:8000/docs`.

### Comandos Importantes

| Acci√≥n | Comando |
| :--- | :--- |
| **Entrenar Modelo** | `python model/train_model.py` |
| **Lanzar UI** | `python ui/app.py` |
| **Lanzar API** | `uvicorn backend.main:app --reload` |
| **Construir Docker** | `docker build -t nebula-sound .` |
| **Correr Docker** | `docker run -p 7860:7860 nebula-sound` |

---

## üß† Detalles T√©cnicos Relevantes

### L√≥gica Clave
El n√∫cleo de la recomendaci√≥n se basa en la **similitud de cosenos** sobre un espacio vectorial h√≠brido:
1.  **Caracter√≠sticas de Texto**: Se concatenan `artist_name`, `artist_genres`, `album_name` y `album_type`. Se procesan con **TF-IDF** (Term Frequency-Inverse Document Frequency) para capturar la esencia sem√°ntica.
2.  **Caracter√≠sticas Num√©ricas**: Se usan atributos como popularidad, duraci√≥n, expl√≠cito, y n√∫mero de tracks. Se normalizan con **StandardScaler** para que tengan el mismo peso que el texto.
3.  **B√∫squeda KNN**: Cuando llega una canci√≥n, se vectoriza igual que el set de entrenamiento y se buscan los $N$ vectores m√°s cercanos (vecinos).

### Decisiones de Dise√±o
- **Sin API de Spotify en tiempo real**: Se decidi√≥ usar un dataset est√°tico (CSV) para garantizar que el proyecto sea aut√≥nomo, reproducible y no dependa de credenciales externas o l√≠mites de API.
- **Frontend en el Backend (Gradio)**: Para el MVP, se integr√≥ la UI directamente con el c√≥digo de l√≥gica (`recommender.py`) en lugar de consumir la API HTTP. Esto simplifica el despliegue local.
- **B√∫squeda Fuzzy**: Se implement√≥ `RapidFuzz` para mejorar la experiencia de usuario, permitiendo encontrar canciones incluso con errores tipogr√°ficos leves.

### Consideraciones de Rendimiento
- **Carga en Memoria**: Los modelos `.pkl` y el DataFrame se cargan completos en RAM al inicio. Esto hace que las consultas sean muy r√°pidas (<100ms), pero requiere memoria suficiente (aprox. 1GB recomendado).
- **Escalabilidad**: El uso de `scikit-learn` `NearestNeighbors` con algoritmo `brute` es eficiente para datasets medianos (miles de canciones), pero para millones de registros se recomendar√≠a un √≠ndice aproximado como **Faiss** o **Annoy**.

---

## ‚úÖ Buenas Pr√°cticas y Recomendaciones

### C√≥mo extender el proyecto
1.  **A√±adir nuevas caracter√≠sticas**:
    - Editar `model/train_model.py` para incluir columnas como `danceability`, `energy`, etc. (si estuvieran en el dataset original).
    - Re-entrenar el modelo con `python model/train_model.py`.
2.  **Integrar Spotify Web API**:
    - Crear un m√≥dulo adaptador en `backend/` para obtener metadatos frescos o car√°tulas de √°lbumes en tiempo real.

### Posibles Mejoras
- **Persistencia**: Guardar las playlists generadas en una base de datos (SQLite/PostgreSQL).
- **Feedback de Usuario**: Permitir al usuario dar "Like" a recomendaciones para re-entrenar o ajustar el modelo en el futuro.
- **Frontend Moderno**: Migrar la UI de Gradio a React o Vue.js consumiendo la FastAPI para una experiencia m√°s personalizada.

### Advertencias
- **Reiniciar tras entrenar**: Si ejecutas `train_model.py`, debes reiniciar el servidor (API o UI) para que cargue los nuevos archivos `.pkl`.
- **Datos Est√°ticos**: Las recomendaciones est√°n limitadas a la m√∫sica existente en el dataset `data/spotify.csv`. Canciones muy nuevas podr√≠an no aparecer.
